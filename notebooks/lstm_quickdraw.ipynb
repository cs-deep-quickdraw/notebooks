{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quickdraw_lstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8YqIzdR0HDZ",
        "colab_type": "code",
        "outputId": "5292d2ac-3816-4fdb-b82b-b8f4a35b7ff5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import struct\n",
        "from struct import unpack\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('device = {}'.format(device))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device = cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8hPIpN33EAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper from: https://github.com/googlecreativelab/quickdraw-dataset/blob/master/examples/binary_file_parser.py\n",
        "def unpack_drawing(file_handle, max_padding):\n",
        "    # Skip key_id: 8, countrycode: 2, recognized: 1, timestamp: 4 = 15\n",
        "    file_handle.read(15)\n",
        "    n_strokes, = unpack('H', file_handle.read(2))\n",
        "    idx = 0\n",
        "\n",
        "    N = 0\n",
        "    strokes = []\n",
        "    for i in range(n_strokes):\n",
        "      n_points, = unpack('H', file_handle.read(2))\n",
        "      N += n_points\n",
        "      fmt = str(n_points) + 'B'\n",
        "      x = unpack(fmt, file_handle.read(n_points))\n",
        "      y = unpack(fmt, file_handle.read(n_points))\n",
        "      strokes.append((x, y))\n",
        "\n",
        "    image = np.zeros((N, 3), dtype=np.float32)\n",
        "\n",
        "\n",
        "    \n",
        "    # Return a tensor of size number of stroke x 3 like here: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/recurrent_quickdraw.md#optional-converting-the-data\n",
        "    for i, (x, y) in enumerate(strokes):\n",
        "        n_points = len(x)\n",
        "        image[idx:idx+n_points, 0] = np.asarray(x)\n",
        "        image[idx:idx+n_points, 1] = np.asarray(y)\n",
        "        idx += n_points\n",
        "        # Mark stroke end with a 1\n",
        "        image[idx -1, 2] = 1\n",
        "\n",
        "\n",
        "    # Preprocessing.\n",
        "    # 1. Size normalization.\n",
        "    lower = np.min(image[:, 0:2], axis=0)\n",
        "    upper = np.max(image[:, 0:2], axis=0)\n",
        "    scale = upper - lower\n",
        "    scale[scale == 0] = 1\n",
        "    image[:, 0:2] = (image[:, 0:2] - lower) / scale\n",
        "    # 2. Compute deltas.\n",
        "    image[1:, 0:2] -= image[0:-1, 0:2]\n",
        "    image = image[1:, :]\n",
        "\n",
        "    return torch.from_numpy(image[:max_padding])\n",
        "\n",
        "\n",
        "def unpack_drawings(filename, max_padding):\n",
        "    with open(filename, 'rb') as f:\n",
        "        while True:\n",
        "            try:\n",
        "                yield unpack_drawing(f, max_padding)\n",
        "            except struct.error:\n",
        "                break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3VBKmsH3OD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib.request\n",
        "from pathlib import Path\n",
        "\n",
        "urllib.request.urlretrieve('https://raw.githubusercontent.com/cs-deep-quickdraw/notebooks/master/100_classes.txt', '100_classes.txt')\n",
        "\n",
        "# Create data dir\n",
        "Path(\"./data\").mkdir(exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5eq4npv3fsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open(\"100_classes.txt\",\"r\")\n",
        "# And for reading use\n",
        "classes = [cls.strip() for cls in f.readlines()]\n",
        "f.close()\n",
        "\n",
        "def download(classes):\n",
        "  base = 'https://storage.googleapis.com/quickdraw_dataset/full/binary/'\n",
        "  for i, c in enumerate(classes):\n",
        "    cls_url = c.replace('_', '%20')\n",
        "    path = base+cls_url+'.bin'\n",
        "    print((1+i)/len(classes), c, path)\n",
        "    urllib.request.urlretrieve(path, 'data/'+c+'.bin')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Yms70h23jSQ",
        "colab_type": "code",
        "outputId": "a20e6e91-b99c-4524-c499-80fb8aa85b21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "download(classes)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.01 drums https://storage.googleapis.com/quickdraw_dataset/full/binary/drums.bin\n",
            "0.02 sun https://storage.googleapis.com/quickdraw_dataset/full/binary/sun.bin\n",
            "0.03 laptop https://storage.googleapis.com/quickdraw_dataset/full/binary/laptop.bin\n",
            "0.04 anvil https://storage.googleapis.com/quickdraw_dataset/full/binary/anvil.bin\n",
            "0.05 baseball_bat https://storage.googleapis.com/quickdraw_dataset/full/binary/baseball%20bat.bin\n",
            "0.06 ladder https://storage.googleapis.com/quickdraw_dataset/full/binary/ladder.bin\n",
            "0.07 eyeglasses https://storage.googleapis.com/quickdraw_dataset/full/binary/eyeglasses.bin\n",
            "0.08 grapes https://storage.googleapis.com/quickdraw_dataset/full/binary/grapes.bin\n",
            "0.09 book https://storage.googleapis.com/quickdraw_dataset/full/binary/book.bin\n",
            "0.1 dumbbell https://storage.googleapis.com/quickdraw_dataset/full/binary/dumbbell.bin\n",
            "0.11 traffic_light https://storage.googleapis.com/quickdraw_dataset/full/binary/traffic%20light.bin\n",
            "0.12 wristwatch https://storage.googleapis.com/quickdraw_dataset/full/binary/wristwatch.bin\n",
            "0.13 wheel https://storage.googleapis.com/quickdraw_dataset/full/binary/wheel.bin\n",
            "0.14 shovel https://storage.googleapis.com/quickdraw_dataset/full/binary/shovel.bin\n",
            "0.15 bread https://storage.googleapis.com/quickdraw_dataset/full/binary/bread.bin\n",
            "0.16 table https://storage.googleapis.com/quickdraw_dataset/full/binary/table.bin\n",
            "0.17 tennis_racquet https://storage.googleapis.com/quickdraw_dataset/full/binary/tennis%20racquet.bin\n",
            "0.18 cloud https://storage.googleapis.com/quickdraw_dataset/full/binary/cloud.bin\n",
            "0.19 chair https://storage.googleapis.com/quickdraw_dataset/full/binary/chair.bin\n",
            "0.2 headphones https://storage.googleapis.com/quickdraw_dataset/full/binary/headphones.bin\n",
            "0.21 face https://storage.googleapis.com/quickdraw_dataset/full/binary/face.bin\n",
            "0.22 eye https://storage.googleapis.com/quickdraw_dataset/full/binary/eye.bin\n",
            "0.23 airplane https://storage.googleapis.com/quickdraw_dataset/full/binary/airplane.bin\n",
            "0.24 snake https://storage.googleapis.com/quickdraw_dataset/full/binary/snake.bin\n",
            "0.25 lollipop https://storage.googleapis.com/quickdraw_dataset/full/binary/lollipop.bin\n",
            "0.26 power_outlet https://storage.googleapis.com/quickdraw_dataset/full/binary/power%20outlet.bin\n",
            "0.27 pants https://storage.googleapis.com/quickdraw_dataset/full/binary/pants.bin\n",
            "0.28 mushroom https://storage.googleapis.com/quickdraw_dataset/full/binary/mushroom.bin\n",
            "0.29 star https://storage.googleapis.com/quickdraw_dataset/full/binary/star.bin\n",
            "0.3 sword https://storage.googleapis.com/quickdraw_dataset/full/binary/sword.bin\n",
            "0.31 clock https://storage.googleapis.com/quickdraw_dataset/full/binary/clock.bin\n",
            "0.32 hot_dog https://storage.googleapis.com/quickdraw_dataset/full/binary/hot%20dog.bin\n",
            "0.33 syringe https://storage.googleapis.com/quickdraw_dataset/full/binary/syringe.bin\n",
            "0.34 stop_sign https://storage.googleapis.com/quickdraw_dataset/full/binary/stop%20sign.bin\n",
            "0.35 mountain https://storage.googleapis.com/quickdraw_dataset/full/binary/mountain.bin\n",
            "0.36 smiley_face https://storage.googleapis.com/quickdraw_dataset/full/binary/smiley%20face.bin\n",
            "0.37 apple https://storage.googleapis.com/quickdraw_dataset/full/binary/apple.bin\n",
            "0.38 bed https://storage.googleapis.com/quickdraw_dataset/full/binary/bed.bin\n",
            "0.39 shorts https://storage.googleapis.com/quickdraw_dataset/full/binary/shorts.bin\n",
            "0.4 broom https://storage.googleapis.com/quickdraw_dataset/full/binary/broom.bin\n",
            "0.41 diving_board https://storage.googleapis.com/quickdraw_dataset/full/binary/diving%20board.bin\n",
            "0.42 flower https://storage.googleapis.com/quickdraw_dataset/full/binary/flower.bin\n",
            "0.43 spider https://storage.googleapis.com/quickdraw_dataset/full/binary/spider.bin\n",
            "0.44 cell_phone https://storage.googleapis.com/quickdraw_dataset/full/binary/cell%20phone.bin\n",
            "0.45 car https://storage.googleapis.com/quickdraw_dataset/full/binary/car.bin\n",
            "0.46 camera https://storage.googleapis.com/quickdraw_dataset/full/binary/camera.bin\n",
            "0.47 tree https://storage.googleapis.com/quickdraw_dataset/full/binary/tree.bin\n",
            "0.48 square https://storage.googleapis.com/quickdraw_dataset/full/binary/square.bin\n",
            "0.49 moon https://storage.googleapis.com/quickdraw_dataset/full/binary/moon.bin\n",
            "0.5 radio https://storage.googleapis.com/quickdraw_dataset/full/binary/radio.bin\n",
            "0.51 hat https://storage.googleapis.com/quickdraw_dataset/full/binary/hat.bin\n",
            "0.52 pizza https://storage.googleapis.com/quickdraw_dataset/full/binary/pizza.bin\n",
            "0.53 axe https://storage.googleapis.com/quickdraw_dataset/full/binary/axe.bin\n",
            "0.54 door https://storage.googleapis.com/quickdraw_dataset/full/binary/door.bin\n",
            "0.55 tent https://storage.googleapis.com/quickdraw_dataset/full/binary/tent.bin\n",
            "0.56 umbrella https://storage.googleapis.com/quickdraw_dataset/full/binary/umbrella.bin\n",
            "0.57 line https://storage.googleapis.com/quickdraw_dataset/full/binary/line.bin\n",
            "0.58 cup https://storage.googleapis.com/quickdraw_dataset/full/binary/cup.bin\n",
            "0.59 fan https://storage.googleapis.com/quickdraw_dataset/full/binary/fan.bin\n",
            "0.6 triangle https://storage.googleapis.com/quickdraw_dataset/full/binary/triangle.bin\n",
            "0.61 basketball https://storage.googleapis.com/quickdraw_dataset/full/binary/basketball.bin\n",
            "0.62 pillow https://storage.googleapis.com/quickdraw_dataset/full/binary/pillow.bin\n",
            "0.63 scissors https://storage.googleapis.com/quickdraw_dataset/full/binary/scissors.bin\n",
            "0.64 t-shirt https://storage.googleapis.com/quickdraw_dataset/full/binary/t-shirt.bin\n",
            "0.65 tooth https://storage.googleapis.com/quickdraw_dataset/full/binary/tooth.bin\n",
            "0.66 alarm_clock https://storage.googleapis.com/quickdraw_dataset/full/binary/alarm%20clock.bin\n",
            "0.67 paper_clip https://storage.googleapis.com/quickdraw_dataset/full/binary/paper%20clip.bin\n",
            "0.68 spoon https://storage.googleapis.com/quickdraw_dataset/full/binary/spoon.bin\n",
            "0.69 microphone https://storage.googleapis.com/quickdraw_dataset/full/binary/microphone.bin\n",
            "0.7 candle https://storage.googleapis.com/quickdraw_dataset/full/binary/candle.bin\n",
            "0.71 pencil https://storage.googleapis.com/quickdraw_dataset/full/binary/pencil.bin\n",
            "0.72 envelope https://storage.googleapis.com/quickdraw_dataset/full/binary/envelope.bin\n",
            "0.73 saw https://storage.googleapis.com/quickdraw_dataset/full/binary/saw.bin\n",
            "0.74 frying_pan https://storage.googleapis.com/quickdraw_dataset/full/binary/frying%20pan.bin\n",
            "0.75 screwdriver https://storage.googleapis.com/quickdraw_dataset/full/binary/screwdriver.bin\n",
            "0.76 helmet https://storage.googleapis.com/quickdraw_dataset/full/binary/helmet.bin\n",
            "0.77 bridge https://storage.googleapis.com/quickdraw_dataset/full/binary/bridge.bin\n",
            "0.78 light_bulb https://storage.googleapis.com/quickdraw_dataset/full/binary/light%20bulb.bin\n",
            "0.79 ceiling_fan https://storage.googleapis.com/quickdraw_dataset/full/binary/ceiling%20fan.bin\n",
            "0.8 key https://storage.googleapis.com/quickdraw_dataset/full/binary/key.bin\n",
            "0.81 donut https://storage.googleapis.com/quickdraw_dataset/full/binary/donut.bin\n",
            "0.82 bird https://storage.googleapis.com/quickdraw_dataset/full/binary/bird.bin\n",
            "0.83 circle https://storage.googleapis.com/quickdraw_dataset/full/binary/circle.bin\n",
            "0.84 beard https://storage.googleapis.com/quickdraw_dataset/full/binary/beard.bin\n",
            "0.85 coffee_cup https://storage.googleapis.com/quickdraw_dataset/full/binary/coffee%20cup.bin\n",
            "0.86 butterfly https://storage.googleapis.com/quickdraw_dataset/full/binary/butterfly.bin\n",
            "0.87 bench https://storage.googleapis.com/quickdraw_dataset/full/binary/bench.bin\n",
            "0.88 rifle https://storage.googleapis.com/quickdraw_dataset/full/binary/rifle.bin\n",
            "0.89 cat https://storage.googleapis.com/quickdraw_dataset/full/binary/cat.bin\n",
            "0.9 sock https://storage.googleapis.com/quickdraw_dataset/full/binary/sock.bin\n",
            "0.91 ice_cream https://storage.googleapis.com/quickdraw_dataset/full/binary/ice%20cream.bin\n",
            "0.92 moustache https://storage.googleapis.com/quickdraw_dataset/full/binary/moustache.bin\n",
            "0.93 suitcase https://storage.googleapis.com/quickdraw_dataset/full/binary/suitcase.bin\n",
            "0.94 hammer https://storage.googleapis.com/quickdraw_dataset/full/binary/hammer.bin\n",
            "0.95 rainbow https://storage.googleapis.com/quickdraw_dataset/full/binary/rainbow.bin\n",
            "0.96 knife https://storage.googleapis.com/quickdraw_dataset/full/binary/knife.bin\n",
            "0.97 cookie https://storage.googleapis.com/quickdraw_dataset/full/binary/cookie.bin\n",
            "0.98 baseball https://storage.googleapis.com/quickdraw_dataset/full/binary/baseball.bin\n",
            "0.99 lightning https://storage.googleapis.com/quickdraw_dataset/full/binary/lightning.bin\n",
            "1.0 bicycle https://storage.googleapis.com/quickdraw_dataset/full/binary/bicycle.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB0d6bjaC8mD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3a6fc50-75cb-40ea-c7ab-e5ed1c527b2f"
      },
      "source": [
        "import os\n",
        "\n",
        "print(len(os.listdir('data')))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBUTUh0MFI11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class StrokeClassifier(nn.Module):\n",
        "  def __init__(self, cv1, cv2, hidden_dim, n_layers, n_classes, bidirectional):\n",
        "    super(StrokeClassifier, self).__init__()\n",
        "    self.hidden_dim = hidden_dim\n",
        "\n",
        "    input_size = 3\n",
        "\n",
        "    self.bn = nn.BatchNorm1d(input_size)\n",
        "\n",
        "    if cv1 is not None:\n",
        "      self.conv1 = nn.Conv1d(input_size, cv1[0], cv1[1])\n",
        "      input_size = cv1[0]\n",
        "\n",
        "      if cv2 is not None:\n",
        "        self.conv2 = nn.Conv1d(input_size, cv2[0], cv2[1])\n",
        "        input_size = cv2[0]\n",
        "    else:\n",
        "      self.conv1 = None\n",
        "      self.conv2 = None\n",
        "    \n",
        "    # The LSTM takes 3 things as input (x, y, isLastPoint) and outputs hidden states with dimensionality hidden_dim\n",
        "    self.lstm = nn.LSTM(input_size, hidden_dim, n_layers, batch_first=True, bidirectional=bidirectional)\n",
        "\n",
        "    # The linear layer maps the LSTM output to a linear space\n",
        "    self.linear = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, n_classes)\n",
        "\n",
        "  def forward(self, strokes):\n",
        "    # BN and Convolution expect NCWH\n",
        "    strokes = self.bn(strokes)\n",
        "    if self.conv1 is not None:\n",
        "      strokes = self.conv1(strokes)\n",
        "\n",
        "      if self.conv2 is not None:\n",
        "        strokes = self.conv2(strokes)\n",
        "\n",
        "    # LSTM expect NHWC\n",
        "    strokes = torch.transpose(strokes, 1, 2)\n",
        "    out, _ = self.lstm(strokes)\n",
        "\n",
        "    # Keep last layer of the NN\n",
        "    out = out[:,-1,:]\n",
        "    out = self.linear(out)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-bafz08v3BK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class DrawDataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        assert len(self.X) == len(self.Y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        return (self.X[idx], self.Y[idx])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQge5B5H-pKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Config:\n",
        "batch_size = 256\n",
        "learning_rate = 0.001\n",
        "\n",
        "hidden_size = 64\n",
        "n_layers = 1\n",
        "train_classes = classes[:]\n",
        "\n",
        "# Use None instead of (n_filters, filter_size) to disable convolution\n",
        "# Note that conv1 = None forces conv2 = None automatically\n",
        "conv1 = None # (128, 5)\n",
        "conv2 = None\n",
        "bidirectional = False\n",
        "\n",
        "N_train = 20000\n",
        "N_val = N_train // 5\n",
        "N_test = N_val\n",
        "N_test_reserved = 20000\n",
        "max_padding = 100\n",
        "n_epochs = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJPBw8l_WLvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import islice\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def extract_dataset(samples_train, samples_val, samples_test, test_reserved, classes, max_padding=100):\n",
        "  X_train = []\n",
        "  X_val = []\n",
        "  X_test = []\n",
        "  y_train = []\n",
        "  y_val = []\n",
        "  y_test = []\n",
        "\n",
        "  for c, cls in enumerate(classes):\n",
        "    drawings = unpack_drawings('data/' + cls + '.bin', max_padding)\n",
        "\n",
        "    # TODO: better way of doing this\n",
        "    for _ in range(samples_train):\n",
        "      X_train.append(next(drawings))\n",
        "      y_train.append(c)\n",
        "\n",
        "    # TODO: itertools\n",
        "    for _ in range(max(0, test_reserved - samples_train)):\n",
        "      next(drawings)\n",
        "\n",
        "    for _ in range(samples_val):\n",
        "      X_val.append(next(drawings))\n",
        "      y_val.append(c)\n",
        "\n",
        "    for _ in range(samples_test):\n",
        "      X_test.append(next(drawings))\n",
        "      y_test.append(c)\n",
        "  \n",
        "    if c % 10 == 0:\n",
        "      print(f\"done extracting class: {cls}: {1 + c} / {len(classes)}\")\n",
        "\n",
        "    drawings.close()\n",
        "    \n",
        "\n",
        "  def norm(X):\n",
        "    return torch.FloatTensor(torch.transpose(pad_sequence(X, batch_first=True), 1, 2))\n",
        "\n",
        "  # XXX: instead of padding like that we could have a moving window:\n",
        "  # Example if we want 100 sequences and we have an image with 200 we can use the windows:\n",
        "  # 0-100, 10-110, ... 100-200 for instance, this would add data\n",
        "  X_train = norm(X_train)\n",
        "  X_val = norm(X_val)\n",
        "  X_test = norm(X_test)\n",
        "  #print(\"training shape\", X_train.shape)\n",
        "  print(\"validation shape\", X_val.shape)\n",
        "  print(\"testing shape\", X_test.shape)\n",
        "  print(\"classes\", len(classes))\n",
        "\n",
        "  return (\n",
        "      DrawDataset(X_train, torch.LongTensor(y_train)), \n",
        "      DrawDataset(X_val, torch.LongTensor(y_val)),\n",
        "      DrawDataset(X_test, torch.LongTensor(y_test)),\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jp5Zo6WcN2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_model(model, loader):\n",
        "  with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for i, (img, label) in enumerate(loader):\n",
        "      img = img.to(device)\n",
        "      label = label.to(device)\n",
        "\n",
        "      out = model(img)\n",
        "\n",
        "      _, pred = torch.max(out.data, 1)\n",
        "\n",
        "      total += label.size(0)\n",
        "      correct += (pred == label).sum().item()\n",
        "\n",
        "    return 100. * correct / total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eysyPVD42XAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_training(losses, accs, n_epochs):\n",
        "  fig, ax1 = plt.subplots()\n",
        "\n",
        "  color = 'tab:red'\n",
        "  ax1.set_xlabel('epoch')\n",
        "  ax1.set_ylabel('training loss', color=color)\n",
        "  ax1.plot(losses, color=color)\n",
        "  ax1.tick_params(axis='y', labelcolor=color)\n",
        "  ax1.set_ylim([0, 5])\n",
        "\n",
        "  ax1.set_xlim([0, n_epochs])\n",
        "  ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "\n",
        "  color = 'tab:blue'\n",
        "  ax2.set_ylabel('validation accuracy', color=color)  # we already handled the x-label with ax1\n",
        "  ax2.plot(accs, color=color)\n",
        "  ax2.tick_params(axis='y', labelcolor=color)\n",
        "  ax2.set_ylim([0, 100])\n",
        "\n",
        "  fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Aua8_l2igl5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "import time\n",
        "\n",
        "def train_model(model, opt, loss_fn, loader, v_loader, n_epochs):\n",
        "\n",
        "  best_acc, best_model = 0, None\n",
        "  losses, accs = [], []\n",
        "  for epoch in range(n_epochs):\n",
        "    start = time.time()\n",
        "    epoch_losses = []\n",
        "    for i, (img, lab) in enumerate(loader):\n",
        "      print(f\"\\rbatch: {i}, current loss: {np.mean(epoch_losses) if epoch_losses else 'NaN'}\", end='')\n",
        "      img = img.to(device)\n",
        "      lab = lab.to(device)\n",
        "\n",
        "      out = model(img)\n",
        "\n",
        "      loss = loss_fn(out, lab)\n",
        "\n",
        "      opt.zero_grad()\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "\n",
        "      epoch_losses.append(loss.item())\n",
        "\n",
        "    print(\"\\rEvaluating model on validation dataset...\", end='')\n",
        "    val_acc = evaluate_model(model, v_loader)\n",
        "    mean_loss = np.mean(epoch_losses)\n",
        "\n",
        "    losses.append(mean_loss)\n",
        "    accs.append(val_acc)\n",
        "\n",
        "    if val_acc > best_acc:\n",
        "      best_acc = val_acc\n",
        "      best_model = copy.deepcopy(model.state_dict())\n",
        "      torch.save(best_model, f\"lstm_epoch_{epoch}_acc_{val_acc}.model\")\n",
        "\n",
        "    print(f\"\\rEpoch: {epoch+1}/{n_epochs}, loss: {mean_loss}, validation accuracy: {val_acc}% took: {time.time() - start} seconds\")\n",
        "\n",
        "  print(f\"Training ended after {n_epochs} ! Best validation accuracy: {best_acc}%\")\n",
        "  try:\n",
        "    plot_training(losses, accs, n_epochs)\n",
        "  except:\n",
        "    print(\"error occurred when plotting losses and accuracy training data\")\n",
        "  return best_model, losses, accs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaXyrAEfvap6",
        "colab_type": "code",
        "outputId": "4efa41a1-d94a-4fe8-b610-42c1a152f0fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# TODO: really take the last 2k images for testing\n",
        "train_dataset, val_dataset, test_dataset = extract_dataset(N_train, N_val, N_test, N_test_reserved, train_classes, max_padding=max_padding)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done extracting class: drums: 1 / 100\n",
            "done extracting class: traffic_light: 11 / 100\n",
            "done extracting class: face: 21 / 100\n",
            "done extracting class: clock: 31 / 100\n",
            "done extracting class: diving_board: 41 / 100\n",
            "done extracting class: hat: 51 / 100\n",
            "done extracting class: basketball: 61 / 100\n",
            "done extracting class: pencil: 71 / 100\n",
            "done extracting class: donut: 81 / 100\n",
            "done extracting class: ice_cream: 91 / 100\n",
            "validation shape torch.Size([400000, 3, 100])\n",
            "testing shape torch.Size([400000, 3, 100])\n",
            "classes 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEGoqxR1y-6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaS_SobxWokC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "model = StrokeClassifier(conv1, conv2, hidden_size, n_layers, len(train_classes), bidirectional).to(device)\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F2SK1L5YWOQ",
        "colab_type": "code",
        "outputId": "4df8b863-1628-44ee-994d-83989aa10941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        }
      },
      "source": [
        "best_model, losses, accs = train_model(model, optimizer, loss_function, train_loader, val_loader, n_epochs)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/10, loss: 3.7877804596445768, validation accuracy: 12.18075% took: 85.73434066772461 seconds\n",
            "Epoch: 2/10, loss: 2.7548682960340343, validation accuracy: 23.64475% took: 84.91592526435852 seconds\n",
            "Epoch: 3/10, loss: 2.0737051215563023, validation accuracy: 34.68525% took: 85.68372511863708 seconds\n",
            "Epoch: 4/10, loss: 1.7293755938572568, validation accuracy: 41.48675% took: 85.85774946212769 seconds\n",
            "Epoch: 5/10, loss: 1.53600292222289, validation accuracy: 45.4705% took: 85.85911870002747 seconds\n",
            "Epoch: 6/10, loss: 1.4183073640251136, validation accuracy: 49.37025% took: 85.58963251113892 seconds\n",
            "Epoch: 7/10, loss: 1.3346304411880798, validation accuracy: 51.46275% took: 86.11428451538086 seconds\n",
            "Epoch: 8/10, loss: 1.2747747892227548, validation accuracy: 51.846% took: 85.57981395721436 seconds\n",
            "Epoch: 9/10, loss: 1.2305504589201042, validation accuracy: 54.52425% took: 85.80500364303589 seconds\n",
            "Epoch: 10/10, loss: 1.1950125450607636, validation accuracy: 55.08175% took: 85.68330955505371 seconds\n",
            "Training ended after 10 ! Best validation accuracy: 55.08175%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bynKPlEifCuI",
        "colab_type": "code",
        "outputId": "ed20a7ce-e463-4126-e739-1eca07ac68ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(f\"Test accuracy: {evaluate_model(model, test_loader)}%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 79.715%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaCHS8rMi7DK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model_path = f'lstm_quickdraw.model.{time.time()}'\n",
        "torch.save(best_model, model_path)\n",
        "\n",
        "print(f\"Model saved at: {model_path}\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}