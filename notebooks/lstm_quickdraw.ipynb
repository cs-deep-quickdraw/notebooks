{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quickdraw_lstm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8YqIzdR0HDZ",
        "colab_type": "code",
        "outputId": "bef83f0f-4624-4ca8-a2d3-28410e2babd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import struct\n",
        "from struct import unpack\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('device = {}'.format(device))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device = cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8hPIpN33EAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper from: https://github.com/googlecreativelab/quickdraw-dataset/blob/master/examples/binary_file_parser.py\n",
        "def unpack_drawing(file_handle):\n",
        "    # Skip key_id: 8, countrycode: 2, recognized: 1, timestamp: 4 = 15\n",
        "    file_handle.read(15)\n",
        "    n_strokes, = unpack('H', file_handle.read(2))\n",
        "    idx = 0\n",
        "\n",
        "    N = 0\n",
        "    strokes = []\n",
        "    for i in range(n_strokes):\n",
        "      n_points, = unpack('H', file_handle.read(2))\n",
        "      N += n_points\n",
        "      fmt = str(n_points) + 'B'\n",
        "      x = unpack(fmt, file_handle.read(n_points))\n",
        "      y = unpack(fmt, file_handle.read(n_points))\n",
        "      strokes.append((x, y))\n",
        "\n",
        "    image = np.zeros((N, 3), dtype=np.float32)\n",
        "\n",
        "\n",
        "    # Return a tensor of size number of stroke x 3 like here: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/recurrent_quickdraw.md#optional-converting-the-data\n",
        "    for i, (x, y) in enumerate(strokes):\n",
        "        n_points = len(x)\n",
        "        image[idx:idx+n_points, 0] = np.asarray(x)\n",
        "        image[idx:idx+n_points, 1] = np.asarray(y)\n",
        "        idx += n_points\n",
        "        # Mark stroke end with a 1\n",
        "        image[idx -1, 2] = 1\n",
        "\n",
        "\n",
        "    # Preprocessing.\n",
        "    # 1. Size normalization.\n",
        "    lower = np.min(image[:, 0:2], axis=0)\n",
        "    upper = np.max(image[:, 0:2], axis=0)\n",
        "    scale = upper - lower\n",
        "    scale[scale == 0] = 1\n",
        "    image[:, 0:2] = (image[:, 0:2] - lower) / scale\n",
        "    # 2. Compute deltas.\n",
        "    image[1:, 0:2] -= image[0:-1, 0:2]\n",
        "    image = image[1:, :]\n",
        "\n",
        "    return torch.FloatTensor(image)\n",
        "\n",
        "\n",
        "def unpack_drawings(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        while True:\n",
        "            try:\n",
        "                yield unpack_drawing(f)\n",
        "            except struct.error:\n",
        "                break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3VBKmsH3OD5",
        "colab_type": "code",
        "outputId": "4a3f5614-3f2f-4cf9-a8b9-e316596a1f7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget 'https://raw.githubusercontent.com/cs-deep-quickdraw/notebooks/master/10_classes.txt'\n",
        "!mkdir data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-13 14:44:33--  https://raw.githubusercontent.com/cs-deep-quickdraw/notebooks/master/10_classes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75 [text/plain]\n",
            "Saving to: ‘10_classes.txt’\n",
            "\n",
            "\r10_classes.txt        0%[                    ]       0  --.-KB/s               \r10_classes.txt      100%[===================>]      75  --.-KB/s    in 0s      \n",
            "\n",
            "2020-02-13 14:44:33 (19.9 MB/s) - ‘10_classes.txt’ saved [75/75]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5eq4npv3fsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib.request\n",
        "\n",
        "f = open(\"10_classes.txt\",\"r\")\n",
        "# And for reading use\n",
        "classes = [cls.strip() for cls in f.readlines()]\n",
        "f.close()\n",
        "\n",
        "def download(classes):\n",
        "  base = 'https://storage.googleapis.com/quickdraw_dataset/full/binary/'\n",
        "  for c in classes:\n",
        "    cls_url = c.replace('_', '%20')\n",
        "    path = base+cls_url+'.bin'\n",
        "    print(path)\n",
        "    urllib.request.urlretrieve(path, 'data/'+c+'.bin')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Yms70h23jSQ",
        "colab_type": "code",
        "outputId": "4e24145a-d2ac-451f-fa65-d15dcf376675",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "download(classes[:10])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://storage.googleapis.com/quickdraw_dataset/full/binary/drums.bin\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/binary/sun.bin\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/binary/laptop.bin\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/binary/anvil.bin\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/binary/baseball%20bat.bin\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/binary/ladder.bin\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/binary/eyeglasses.bin\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/binary/grapes.bin\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/binary/book.bin\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/binary/dumbbell.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk--4Ijv4Lzn",
        "colab_type": "code",
        "outputId": "3c74b2e7-2709-46f0-801d-3b5b15a39e6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls data"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "anvil.bin\t  book.bin   dumbbell.bin    grapes.bin  laptop.bin\n",
            "baseball_bat.bin  drums.bin  eyeglasses.bin  ladder.bin  sun.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or6BSe083lr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i_drawings = unpack_drawings(\"data/anvil.bin\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doIPk9wz4nnQ",
        "colab_type": "code",
        "outputId": "d2a54a56-f8d0-475b-e618-a77fc926ab2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from pprint import pprint\n",
        "pprint(next(i_drawings)[:2])\n",
        "pprint(next(i_drawings)[:2])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.2235, -0.0404,  0.0000],\n",
            "        [ 0.3176, -0.0101,  0.0000]])\n",
            "tensor([[-0.0118,  0.3372,  0.0000],\n",
            "        [ 0.0984, -0.0116,  0.0000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBUTUh0MFI11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class StrokeClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, hidden_dim, n_classes):\n",
        "    super(StrokeClassifier, self).__init__()\n",
        "    self.hidden_dim = hidden_dim\n",
        "\n",
        "    # The LSTM takes 3 things as input (x, y, isLastPoint) and outputs hidden states with dimensionality hidden_dim\n",
        "    self.lstm = nn.LSTM(3, hidden_dim, batch_first=True)\n",
        "\n",
        "    # The linear layer maps the LSTM output to a linear space\n",
        "    self.linear = nn.Linear(hidden_dim, n_classes)\n",
        "\n",
        "  def forward(self, strokes):\n",
        "    # initial states\n",
        "    h0 = torch.zeros(1, strokes.size(0), self.hidden_dim).to(device)\n",
        "    c0 = torch.zeros(1, strokes.size(0), self.hidden_dim).to(device)\n",
        "\n",
        "    out, _ = self.lstm(strokes)\n",
        "    # Keep last layer of the NN\n",
        "    out = out[:,-1,:]\n",
        "    out = self.linear(out)\n",
        "    return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-bafz08v3BK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class DrawDataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        assert len(self.X) == len(self.Y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        return [torch.Tensor(self.X[idx]).type('torch.FloatTensor'), self.Y[idx]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQge5B5H-pKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Config:\n",
        "batch_size = 256\n",
        "learning_rate = 0.01\n",
        "hidden_size = 64\n",
        "train_classes = classes[:]\n",
        "N_train = 10000\n",
        "N_test = 2000\n",
        "max_padding = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJPBw8l_WLvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import islice\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def extract_train_test(samples_train, samples_test, classes, max_padding=100):\n",
        "  X_train = []\n",
        "  X_test = []\n",
        "  y_train = []\n",
        "  y_test = []\n",
        "\n",
        "  for c, cls in enumerate(classes):\n",
        "    drawings = unpack_drawings('data/' + cls + '.bin')\n",
        "\n",
        "    # TODO: better way of doing this\n",
        "    for i in range(samples_train):\n",
        "      X_train.append(next(drawings))\n",
        "      y_train.append(c)\n",
        "\n",
        "    for i in range(samples_test):\n",
        "      X_test.append(next(drawings))\n",
        "      y_test.append(c)\n",
        "    \n",
        "  X_train = pad_sequence(X_train, batch_first=True)[:, :max_padding, :]\n",
        "  X_test = pad_sequence(X_test, batch_first=True)[:, :max_padding, :]\n",
        "  print(\"training shape\", X_train.shape)\n",
        "  print(\"testing shape\", X_test.shape)\n",
        "  print(\"classes\", len(classes))\n",
        "\n",
        "  return DrawDataset(X_train, y_train), DrawDataset(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaXyrAEfvap6",
        "colab_type": "code",
        "outputId": "7efe1e97-01b1-4327-91de-2b868f081ed4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# TODO: really take the last 2k images for testing\n",
        "train_dataset, test_dataset = extract_train_test(N_train, N_test, train_classes, max_padding=max_padding)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training shape torch.Size([100000, 50, 3])\n",
            "testing shape torch.Size([20000, 50, 3])\n",
            "classes 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEGoqxR1y-6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaS_SobxWokC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "model = StrokeClassifier(hidden_size, len(train_classes)).to(device)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F2SK1L5YWOQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "b1e00345-4865-490a-93c9-16cedb8a28bb"
      },
      "source": [
        "# BAD don't do that much epochs\n",
        "last_loss = None\n",
        "for epoch in range(50):\n",
        "  print(f\"Epoch: {epoch}, last_loss: {last_loss}\")\n",
        "\n",
        "  for i, (img, lab) in enumerate(train_loader):\n",
        "    img = img.to(device)\n",
        "    lab = torch.LongTensor(lab).to(device)\n",
        "\n",
        "    out = model(img)\n",
        "\n",
        "    loss = loss_function(out, lab)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    last_loss = loss.item()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, last_loss: None\n",
            "Epoch: 1, last_loss: 0.955832839012146\n",
            "Epoch: 2, last_loss: 0.6931900978088379\n",
            "Epoch: 3, last_loss: 0.5070900917053223\n",
            "Epoch: 4, last_loss: 0.5635804533958435\n",
            "Epoch: 5, last_loss: 0.39240333437919617\n",
            "Epoch: 6, last_loss: 0.3495434522628784\n",
            "Epoch: 7, last_loss: 0.49082279205322266\n",
            "Epoch: 8, last_loss: 0.26588380336761475\n",
            "Epoch: 9, last_loss: 0.2726176679134369\n",
            "Epoch: 10, last_loss: 0.2209448367357254\n",
            "Epoch: 11, last_loss: 0.20589976012706757\n",
            "Epoch: 12, last_loss: 0.27800363302230835\n",
            "Epoch: 13, last_loss: 0.2930254638195038\n",
            "Epoch: 14, last_loss: 0.23719331622123718\n",
            "Epoch: 15, last_loss: 0.1916734278202057\n",
            "Epoch: 16, last_loss: 0.3294978439807892\n",
            "Epoch: 17, last_loss: 0.274522602558136\n",
            "Epoch: 18, last_loss: 0.18168215453624725\n",
            "Epoch: 19, last_loss: 0.25937822461128235\n",
            "Epoch: 20, last_loss: 0.28454890847206116\n",
            "Epoch: 21, last_loss: 0.1985488384962082\n",
            "Epoch: 22, last_loss: 0.17741376161575317\n",
            "Epoch: 23, last_loss: 0.30256128311157227\n",
            "Epoch: 24, last_loss: 0.18741008639335632\n",
            "Epoch: 25, last_loss: 0.12808682024478912\n",
            "Epoch: 26, last_loss: 0.1437753140926361\n",
            "Epoch: 27, last_loss: 0.25998395681381226\n",
            "Epoch: 28, last_loss: 0.21765513718128204\n",
            "Epoch: 29, last_loss: 0.22930772602558136\n",
            "Epoch: 30, last_loss: 0.17494364082813263\n",
            "Epoch: 31, last_loss: 0.1880575269460678\n",
            "Epoch: 32, last_loss: 0.1491297334432602\n",
            "Epoch: 33, last_loss: 0.09532003104686737\n",
            "Epoch: 34, last_loss: 0.1826196014881134\n",
            "Epoch: 35, last_loss: 0.1682448387145996\n",
            "Epoch: 36, last_loss: 0.13294532895088196\n",
            "Epoch: 37, last_loss: 0.13503582775592804\n",
            "Epoch: 38, last_loss: 0.1038721427321434\n",
            "Epoch: 39, last_loss: 0.1428133100271225\n",
            "Epoch: 40, last_loss: 0.19774176180362701\n",
            "Epoch: 41, last_loss: 0.21925000846385956\n",
            "Epoch: 42, last_loss: 0.11957788467407227\n",
            "Epoch: 43, last_loss: 0.22558602690696716\n",
            "Epoch: 44, last_loss: 0.2967299222946167\n",
            "Epoch: 45, last_loss: 0.12615135312080383\n",
            "Epoch: 46, last_loss: 0.23854593932628632\n",
            "Epoch: 47, last_loss: 0.269395112991333\n",
            "Epoch: 48, last_loss: 0.16091305017471313\n",
            "Epoch: 49, last_loss: 0.12974882125854492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jp5Zo6WcN2z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "312146bf-908c-44f0-a6c7-f4df8c539955"
      },
      "source": [
        "# Test\n",
        "\n",
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  \n",
        "  for i, (img, label) in enumerate(test_loader):\n",
        "    img = img.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    out = model(img)\n",
        "\n",
        "    _, pred = torch.max(out.data, 1)\n",
        "\n",
        "    total += label.size(0)\n",
        "    correct += (pred == label).sum().item()\n",
        "\n",
        "  print('Test Accuracy: {}%'.format(100. * correct / total) )"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 90.655%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bynKPlEifCuI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}