{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quickdraw_lstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8YqIzdR0HDZ",
        "colab_type": "code",
        "outputId": "785beb0d-d4be-4a40-d172-288642c7451f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import struct\n",
        "from struct import unpack\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('device = {}'.format(device))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device = cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8hPIpN33EAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper from: https://github.com/googlecreativelab/quickdraw-dataset/blob/master/examples/binary_file_parser.py\n",
        "def unpack_drawing(file_handle):\n",
        "    # Skip key_id: 8, countrycode: 2, recognized: 1, timestamp: 4 = 15\n",
        "    file_handle.read(15)\n",
        "    n_strokes, = unpack('H', file_handle.read(2))\n",
        "    idx = 0\n",
        "\n",
        "    N = 0\n",
        "    strokes = []\n",
        "    for i in range(n_strokes):\n",
        "      n_points, = unpack('H', file_handle.read(2))\n",
        "      N += n_points\n",
        "      fmt = str(n_points) + 'B'\n",
        "      x = unpack(fmt, file_handle.read(n_points))\n",
        "      y = unpack(fmt, file_handle.read(n_points))\n",
        "      strokes.append((x, y))\n",
        "\n",
        "    image = np.zeros((N, 3), dtype=np.float32)\n",
        "\n",
        "\n",
        "    # Return a tensor of size number of stroke x 3 like here: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/recurrent_quickdraw.md#optional-converting-the-data\n",
        "    for i, (x, y) in enumerate(strokes):\n",
        "        n_points = len(x)\n",
        "        image[idx:idx+n_points, 0] = np.asarray(x)\n",
        "        image[idx:idx+n_points, 1] = np.asarray(y)\n",
        "        idx += n_points\n",
        "        # Mark stroke end with a 1\n",
        "        image[idx -1, 2] = 1\n",
        "\n",
        "\n",
        "    # Preprocessing.\n",
        "    # 1. Size normalization.\n",
        "    lower = np.min(image[:, 0:2], axis=0)\n",
        "    upper = np.max(image[:, 0:2], axis=0)\n",
        "    scale = upper - lower\n",
        "    scale[scale == 0] = 1\n",
        "    image[:, 0:2] = (image[:, 0:2] - lower) / scale\n",
        "    # 2. Compute deltas.\n",
        "    image[1:, 0:2] -= image[0:-1, 0:2]\n",
        "    image = image[1:, :]\n",
        "\n",
        "    return torch.FloatTensor(image)\n",
        "\n",
        "\n",
        "def unpack_drawings(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        while True:\n",
        "            try:\n",
        "                yield unpack_drawing(f)\n",
        "            except struct.error:\n",
        "                break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3VBKmsH3OD5",
        "colab_type": "code",
        "outputId": "ac9dc33c-cf77-4c28-eb44-7c4f23ffb390",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "import urllib.request\n",
        "from pathlib import Path\n",
        "\n",
        "urllib.request.urlretrieve('https://raw.githubusercontent.com/cs-deep-quickdraw/notebooks/master/100_classes.txt', '100_classes.txt')\n",
        "\n",
        "# Create data dir\n",
        "Path(\"./data\").mkdir(exist_ok=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-21 14:21:23--  https://raw.githubusercontent.com/cs-deep-quickdraw/notebooks/master/100_classes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 760 [text/plain]\n",
            "Saving to: ‘100_classes.txt’\n",
            "\n",
            "100_classes.txt     100%[===================>]     760  --.-KB/s    in 0s      \n",
            "\n",
            "2020-02-21 14:21:28 (201 MB/s) - ‘100_classes.txt’ saved [760/760]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5eq4npv3fsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open(\"100_classes.txt\",\"r\")\n",
        "# And for reading use\n",
        "classes = [cls.strip() for cls in f.readlines()]\n",
        "f.close()\n",
        "\n",
        "def download(classes):\n",
        "  base = 'https://storage.googleapis.com/quickdraw_dataset/full/binary/'\n",
        "  for i, c in enumerate(classes):\n",
        "    cls_url = c.replace('_', '%20')\n",
        "    path = base+cls_url+'.bin'\n",
        "    print((1+i)/len(classes), c, path)\n",
        "    urllib.request.urlretrieve(path, 'data/'+c+'.bin')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Yms70h23jSQ",
        "colab_type": "code",
        "outputId": "72eaf725-e089-4969-9f29-21e59e61becc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "download(classes)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.01 drums https://storage.googleapis.com/quickdraw_dataset/full/binary/drums.bin\n",
            "0.02 sun https://storage.googleapis.com/quickdraw_dataset/full/binary/sun.bin\n",
            "0.03 laptop https://storage.googleapis.com/quickdraw_dataset/full/binary/laptop.bin\n",
            "0.04 anvil https://storage.googleapis.com/quickdraw_dataset/full/binary/anvil.bin\n",
            "0.05 baseball_bat https://storage.googleapis.com/quickdraw_dataset/full/binary/baseball%20bat.bin\n",
            "0.06 ladder https://storage.googleapis.com/quickdraw_dataset/full/binary/ladder.bin\n",
            "0.07 eyeglasses https://storage.googleapis.com/quickdraw_dataset/full/binary/eyeglasses.bin\n",
            "0.08 grapes https://storage.googleapis.com/quickdraw_dataset/full/binary/grapes.bin\n",
            "0.09 book https://storage.googleapis.com/quickdraw_dataset/full/binary/book.bin\n",
            "0.1 dumbbell https://storage.googleapis.com/quickdraw_dataset/full/binary/dumbbell.bin\n",
            "0.11 traffic_light https://storage.googleapis.com/quickdraw_dataset/full/binary/traffic%20light.bin\n",
            "0.12 wristwatch https://storage.googleapis.com/quickdraw_dataset/full/binary/wristwatch.bin\n",
            "0.13 wheel https://storage.googleapis.com/quickdraw_dataset/full/binary/wheel.bin\n",
            "0.14 shovel https://storage.googleapis.com/quickdraw_dataset/full/binary/shovel.bin\n",
            "0.15 bread https://storage.googleapis.com/quickdraw_dataset/full/binary/bread.bin\n",
            "0.16 table https://storage.googleapis.com/quickdraw_dataset/full/binary/table.bin\n",
            "0.17 tennis_racquet https://storage.googleapis.com/quickdraw_dataset/full/binary/tennis%20racquet.bin\n",
            "0.18 cloud https://storage.googleapis.com/quickdraw_dataset/full/binary/cloud.bin\n",
            "0.19 chair https://storage.googleapis.com/quickdraw_dataset/full/binary/chair.bin\n",
            "0.2 headphones https://storage.googleapis.com/quickdraw_dataset/full/binary/headphones.bin\n",
            "0.21 face https://storage.googleapis.com/quickdraw_dataset/full/binary/face.bin\n",
            "0.22 eye https://storage.googleapis.com/quickdraw_dataset/full/binary/eye.bin\n",
            "0.23 airplane https://storage.googleapis.com/quickdraw_dataset/full/binary/airplane.bin\n",
            "0.24 snake https://storage.googleapis.com/quickdraw_dataset/full/binary/snake.bin\n",
            "0.25 lollipop https://storage.googleapis.com/quickdraw_dataset/full/binary/lollipop.bin\n",
            "0.26 power_outlet https://storage.googleapis.com/quickdraw_dataset/full/binary/power%20outlet.bin\n",
            "0.27 pants https://storage.googleapis.com/quickdraw_dataset/full/binary/pants.bin\n",
            "0.28 mushroom https://storage.googleapis.com/quickdraw_dataset/full/binary/mushroom.bin\n",
            "0.29 star https://storage.googleapis.com/quickdraw_dataset/full/binary/star.bin\n",
            "0.3 sword https://storage.googleapis.com/quickdraw_dataset/full/binary/sword.bin\n",
            "0.31 clock https://storage.googleapis.com/quickdraw_dataset/full/binary/clock.bin\n",
            "0.32 hot_dog https://storage.googleapis.com/quickdraw_dataset/full/binary/hot%20dog.bin\n",
            "0.33 syringe https://storage.googleapis.com/quickdraw_dataset/full/binary/syringe.bin\n",
            "0.34 stop_sign https://storage.googleapis.com/quickdraw_dataset/full/binary/stop%20sign.bin\n",
            "0.35 mountain https://storage.googleapis.com/quickdraw_dataset/full/binary/mountain.bin\n",
            "0.36 smiley_face https://storage.googleapis.com/quickdraw_dataset/full/binary/smiley%20face.bin\n",
            "0.37 apple https://storage.googleapis.com/quickdraw_dataset/full/binary/apple.bin\n",
            "0.38 bed https://storage.googleapis.com/quickdraw_dataset/full/binary/bed.bin\n",
            "0.39 shorts https://storage.googleapis.com/quickdraw_dataset/full/binary/shorts.bin\n",
            "0.4 broom https://storage.googleapis.com/quickdraw_dataset/full/binary/broom.bin\n",
            "0.41 diving_board https://storage.googleapis.com/quickdraw_dataset/full/binary/diving%20board.bin\n",
            "0.42 flower https://storage.googleapis.com/quickdraw_dataset/full/binary/flower.bin\n",
            "0.43 spider https://storage.googleapis.com/quickdraw_dataset/full/binary/spider.bin\n",
            "0.44 cell_phone https://storage.googleapis.com/quickdraw_dataset/full/binary/cell%20phone.bin\n",
            "0.45 car https://storage.googleapis.com/quickdraw_dataset/full/binary/car.bin\n",
            "0.46 camera https://storage.googleapis.com/quickdraw_dataset/full/binary/camera.bin\n",
            "0.47 tree https://storage.googleapis.com/quickdraw_dataset/full/binary/tree.bin\n",
            "0.48 square https://storage.googleapis.com/quickdraw_dataset/full/binary/square.bin\n",
            "0.49 moon https://storage.googleapis.com/quickdraw_dataset/full/binary/moon.bin\n",
            "0.5 radio https://storage.googleapis.com/quickdraw_dataset/full/binary/radio.bin\n",
            "0.51 hat https://storage.googleapis.com/quickdraw_dataset/full/binary/hat.bin\n",
            "0.52 pizza https://storage.googleapis.com/quickdraw_dataset/full/binary/pizza.bin\n",
            "0.53 axe https://storage.googleapis.com/quickdraw_dataset/full/binary/axe.bin\n",
            "0.54 door https://storage.googleapis.com/quickdraw_dataset/full/binary/door.bin\n",
            "0.55 tent https://storage.googleapis.com/quickdraw_dataset/full/binary/tent.bin\n",
            "0.56 umbrella https://storage.googleapis.com/quickdraw_dataset/full/binary/umbrella.bin\n",
            "0.57 line https://storage.googleapis.com/quickdraw_dataset/full/binary/line.bin\n",
            "0.58 cup https://storage.googleapis.com/quickdraw_dataset/full/binary/cup.bin\n",
            "0.59 fan https://storage.googleapis.com/quickdraw_dataset/full/binary/fan.bin\n",
            "0.6 triangle https://storage.googleapis.com/quickdraw_dataset/full/binary/triangle.bin\n",
            "0.61 basketball https://storage.googleapis.com/quickdraw_dataset/full/binary/basketball.bin\n",
            "0.62 pillow https://storage.googleapis.com/quickdraw_dataset/full/binary/pillow.bin\n",
            "0.63 scissors https://storage.googleapis.com/quickdraw_dataset/full/binary/scissors.bin\n",
            "0.64 t-shirt https://storage.googleapis.com/quickdraw_dataset/full/binary/t-shirt.bin\n",
            "0.65 tooth https://storage.googleapis.com/quickdraw_dataset/full/binary/tooth.bin\n",
            "0.66 alarm_clock https://storage.googleapis.com/quickdraw_dataset/full/binary/alarm%20clock.bin\n",
            "0.67 paper_clip https://storage.googleapis.com/quickdraw_dataset/full/binary/paper%20clip.bin\n",
            "0.68 spoon https://storage.googleapis.com/quickdraw_dataset/full/binary/spoon.bin\n",
            "0.69 microphone https://storage.googleapis.com/quickdraw_dataset/full/binary/microphone.bin\n",
            "0.7 candle https://storage.googleapis.com/quickdraw_dataset/full/binary/candle.bin\n",
            "0.71 pencil https://storage.googleapis.com/quickdraw_dataset/full/binary/pencil.bin\n",
            "0.72 envelope https://storage.googleapis.com/quickdraw_dataset/full/binary/envelope.bin\n",
            "0.73 saw https://storage.googleapis.com/quickdraw_dataset/full/binary/saw.bin\n",
            "0.74 frying_pan https://storage.googleapis.com/quickdraw_dataset/full/binary/frying%20pan.bin\n",
            "0.75 screwdriver https://storage.googleapis.com/quickdraw_dataset/full/binary/screwdriver.bin\n",
            "0.76 helmet https://storage.googleapis.com/quickdraw_dataset/full/binary/helmet.bin\n",
            "0.77 bridge https://storage.googleapis.com/quickdraw_dataset/full/binary/bridge.bin\n",
            "0.78 light_bulb https://storage.googleapis.com/quickdraw_dataset/full/binary/light%20bulb.bin\n",
            "0.79 ceiling_fan https://storage.googleapis.com/quickdraw_dataset/full/binary/ceiling%20fan.bin\n",
            "0.8 key https://storage.googleapis.com/quickdraw_dataset/full/binary/key.bin\n",
            "0.81 donut https://storage.googleapis.com/quickdraw_dataset/full/binary/donut.bin\n",
            "0.82 bird https://storage.googleapis.com/quickdraw_dataset/full/binary/bird.bin\n",
            "0.83 circle https://storage.googleapis.com/quickdraw_dataset/full/binary/circle.bin\n",
            "0.84 beard https://storage.googleapis.com/quickdraw_dataset/full/binary/beard.bin\n",
            "0.85 coffee_cup https://storage.googleapis.com/quickdraw_dataset/full/binary/coffee%20cup.bin\n",
            "0.86 butterfly https://storage.googleapis.com/quickdraw_dataset/full/binary/butterfly.bin\n",
            "0.87 bench https://storage.googleapis.com/quickdraw_dataset/full/binary/bench.bin\n",
            "0.88 rifle https://storage.googleapis.com/quickdraw_dataset/full/binary/rifle.bin\n",
            "0.89 cat https://storage.googleapis.com/quickdraw_dataset/full/binary/cat.bin\n",
            "0.9 sock https://storage.googleapis.com/quickdraw_dataset/full/binary/sock.bin\n",
            "0.91 ice_cream https://storage.googleapis.com/quickdraw_dataset/full/binary/ice%20cream.bin\n",
            "0.92 moustache https://storage.googleapis.com/quickdraw_dataset/full/binary/moustache.bin\n",
            "0.93 suitcase https://storage.googleapis.com/quickdraw_dataset/full/binary/suitcase.bin\n",
            "0.94 hammer https://storage.googleapis.com/quickdraw_dataset/full/binary/hammer.bin\n",
            "0.95 rainbow https://storage.googleapis.com/quickdraw_dataset/full/binary/rainbow.bin\n",
            "0.96 knife https://storage.googleapis.com/quickdraw_dataset/full/binary/knife.bin\n",
            "0.97 cookie https://storage.googleapis.com/quickdraw_dataset/full/binary/cookie.bin\n",
            "0.98 baseball https://storage.googleapis.com/quickdraw_dataset/full/binary/baseball.bin\n",
            "0.99 lightning https://storage.googleapis.com/quickdraw_dataset/full/binary/lightning.bin\n",
            "1.0 bicycle https://storage.googleapis.com/quickdraw_dataset/full/binary/bicycle.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk--4Ijv4Lzn",
        "colab_type": "code",
        "outputId": "d07c791e-d334-42e2-e5fe-19d5899f4575",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "!ls data"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "airplane.bin\t  circle.bin\t    key.bin\t      shorts.bin\n",
            "alarm_clock.bin   clock.bin\t    knife.bin\t      shovel.bin\n",
            "anvil.bin\t  cloud.bin\t    ladder.bin\t      smiley_face.bin\n",
            "apple.bin\t  coffee_cup.bin    laptop.bin\t      snake.bin\n",
            "axe.bin\t\t  cookie.bin\t    light_bulb.bin    sock.bin\n",
            "baseball_bat.bin  cup.bin\t    lightning.bin     spider.bin\n",
            "baseball.bin\t  diving_board.bin  line.bin\t      spoon.bin\n",
            "basketball.bin\t  donut.bin\t    lollipop.bin      square.bin\n",
            "beard.bin\t  door.bin\t    microphone.bin    star.bin\n",
            "bed.bin\t\t  drums.bin\t    moon.bin\t      stop_sign.bin\n",
            "bench.bin\t  dumbbell.bin\t    mountain.bin      suitcase.bin\n",
            "bicycle.bin\t  envelope.bin\t    moustache.bin     sun.bin\n",
            "bird.bin\t  eye.bin\t    mushroom.bin      sword.bin\n",
            "book.bin\t  eyeglasses.bin    pants.bin\t      syringe.bin\n",
            "bread.bin\t  face.bin\t    paper_clip.bin    table.bin\n",
            "bridge.bin\t  fan.bin\t    pencil.bin\t      tennis_racquet.bin\n",
            "broom.bin\t  flower.bin\t    pillow.bin\t      tent.bin\n",
            "butterfly.bin\t  frying_pan.bin    pizza.bin\t      tooth.bin\n",
            "camera.bin\t  grapes.bin\t    power_outlet.bin  traffic_light.bin\n",
            "candle.bin\t  hammer.bin\t    radio.bin\t      tree.bin\n",
            "car.bin\t\t  hat.bin\t    rainbow.bin       triangle.bin\n",
            "cat.bin\t\t  headphones.bin    rifle.bin\t      t-shirt.bin\n",
            "ceiling_fan.bin   helmet.bin\t    saw.bin\t      umbrella.bin\n",
            "cell_phone.bin\t  hot_dog.bin\t    scissors.bin      wheel.bin\n",
            "chair.bin\t  ice_cream.bin     screwdriver.bin   wristwatch.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or6BSe083lr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i_drawings = unpack_drawings(\"data/anvil.bin\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doIPk9wz4nnQ",
        "colab_type": "code",
        "outputId": "fd4ae3ca-8f2f-4b68-dc81-473641d4e1d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from pprint import pprint\n",
        "pprint(next(i_drawings)[:2])\n",
        "pprint(next(i_drawings)[:2])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.2235, -0.0404,  0.0000],\n",
            "        [ 0.3176, -0.0101,  0.0000]])\n",
            "tensor([[-0.0118,  0.3372,  0.0000],\n",
            "        [ 0.0984, -0.0116,  0.0000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBUTUh0MFI11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class StrokeClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, cv1, hidden_dim, n_layers, n_classes, bidirectional):\n",
        "    super(StrokeClassifier, self).__init__()\n",
        "    self.hidden_dim = hidden_dim\n",
        "\n",
        "    input_size = 3\n",
        "\n",
        "    self.bn = nn.BatchNorm1d(input_size)\n",
        "    self.conv1 = nn.Conv1d(input_size, cv1[0], cv1[1])\n",
        "    \n",
        "    # The LSTM takes 3 things as input (x, y, isLastPoint) and outputs hidden states with dimensionality hidden_dim\n",
        "    self.lstm = nn.LSTM(cv1[0], hidden_dim, n_layers, batch_first=True, bidirectional=bidirectional)\n",
        "\n",
        "    # The linear layer maps the LSTM output to a linear space\n",
        "    self.linear = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, n_classes)\n",
        "\n",
        "  def forward(self, strokes):\n",
        "    # BN and Convolution expect NCWH\n",
        "    strokes = self.bn(strokes)\n",
        "    strokes = self.conv1(strokes)\n",
        "\n",
        "    # LSTM expect NHWC\n",
        "    strokes = torch.transpose(strokes, 1, 2)\n",
        "    out, _ = self.lstm(strokes)\n",
        "\n",
        "    # Keep last layer of the NN\n",
        "    out = out[:,-1,:]\n",
        "    out = self.linear(out)\n",
        "    return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-bafz08v3BK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class DrawDataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        assert len(self.X) == len(self.Y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        return [torch.Tensor(self.X[idx]).type('torch.FloatTensor'), self.Y[idx]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQge5B5H-pKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Config:\n",
        "batch_size = 256\n",
        "learning_rate = 0.001\n",
        "\n",
        "hidden_size = 64\n",
        "n_layers = 2\n",
        "train_classes = classes[:]\n",
        "conv1 = (128, 5)\n",
        "bidirectional = True\n",
        "\n",
        "N_train = 13000\n",
        "N_val = 2000\n",
        "N_test = 200\n",
        "N_test_reserved = 20000\n",
        "max_padding = 100\n",
        "n_epochs = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJPBw8l_WLvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import islice\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def extract_dataset(samples_train, samples_val, samples_test, test_reserved, classes, max_padding=100):\n",
        "  X_train = []\n",
        "  X_val = []\n",
        "  X_test = []\n",
        "  y_train = []\n",
        "  y_val = []\n",
        "  y_test = []\n",
        "\n",
        "  for c, cls in enumerate(classes):\n",
        "    drawings = unpack_drawings('data/' + cls + '.bin')\n",
        "\n",
        "    # TODO: better way of doing this\n",
        "    for _ in range(samples_train):\n",
        "      X_train.append(next(drawings))\n",
        "      y_train.append(c)\n",
        "\n",
        "    # TODO: itertools\n",
        "    for _ in range(max(0, test_reserved - samples_train)):\n",
        "      next(drawings)\n",
        "\n",
        "    for _ in range(samples_val):\n",
        "      X_val.append(next(drawings))\n",
        "      y_val.append(c)\n",
        "\n",
        "    for _ in range(samples_test):\n",
        "      X_test.append(next(drawings))\n",
        "      y_test.append(c)\n",
        "  \n",
        "    if c % 10 == 0:\n",
        "      print(f\"done extracting class: {cls}: {1 + c} / {len(classes)}\")\n",
        "    \n",
        "\n",
        "  def norm(X):\n",
        "    return torch.transpose(pad_sequence(X, batch_first=True)[:, :max_padding, :], 1, 2)\n",
        "\n",
        "  # XXX: instead of padding like that we could have a moving window:\n",
        "  # Example if we want 100 sequences and we have an image with 200 we can use the windows:\n",
        "  # 0-100, 10-110, ... 100-200 for instance, this would add data\n",
        "  X_train = norm(X_train)\n",
        "  X_val = norm(X_val)\n",
        "  X_test = norm(X_test)\n",
        "  print(\"training shape\", X_train.shape)\n",
        "  print(\"validation shape\", X_val.shape)\n",
        "  print(\"testing shape\", X_test.shape)\n",
        "  print(\"classes\", len(classes))\n",
        "\n",
        "  return DrawDataset(X_train, y_train), DrawDataset(X_val, y_val), DrawDataset(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jp5Zo6WcN2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_model(model, loader):\n",
        "  with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for i, (img, label) in enumerate(loader):\n",
        "      img = img.to(device)\n",
        "      label = label.to(device)\n",
        "\n",
        "      out = model(img)\n",
        "\n",
        "      _, pred = torch.max(out.data, 1)\n",
        "\n",
        "      total += label.size(0)\n",
        "      correct += (pred == label).sum().item()\n",
        "\n",
        "    return 100. * correct / total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eysyPVD42XAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_training(losses, accs, n_epochs):\n",
        "  fig, ax1 = plt.subplots()\n",
        "\n",
        "  color = 'tab:red'\n",
        "  ax1.set_xlabel('epoch')\n",
        "  ax1.set_ylabel('training loss', color=color)\n",
        "  ax1.plot(losses, color=color)\n",
        "  ax1.tick_params(axis='y', labelcolor=color)\n",
        "  ax1.set_ylim([0, 5])\n",
        "\n",
        "  ax1.set_xlim([0, n_epochs])\n",
        "  ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "\n",
        "  color = 'tab:blue'\n",
        "  ax2.set_ylabel('validation accuracy', color=color)  # we already handled the x-label with ax1\n",
        "  ax2.plot(accs, color=color)\n",
        "  ax2.tick_params(axis='y', labelcolor=color)\n",
        "  ax2.set_ylim([0, 100])\n",
        "\n",
        "  fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Aua8_l2igl5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "import time\n",
        "\n",
        "def train_model(model, opt, loss_fn, loader, v_loader, n_epochs):\n",
        "\n",
        "  best_acc, best_model = 0, None\n",
        "  losses, accs = [], []\n",
        "  for epoch in range(n_epochs):\n",
        "    start = time.time()\n",
        "    epoch_losses = []\n",
        "    for i, (img, lab) in enumerate(loader):\n",
        "      print(f\"\\rbatch: {i}, current loss: {np.mean(epoch_losses) if epoch_losses else 'NaN'}\", end='')\n",
        "      img = img.to(device)\n",
        "      lab = torch.LongTensor(lab).to(device)\n",
        "\n",
        "      out = model(img)\n",
        "\n",
        "      loss = loss_fn(out, lab)\n",
        "\n",
        "      opt.zero_grad()\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "\n",
        "      epoch_losses.append(loss.item())\n",
        "\n",
        "    print(\"\\rEvaluating model on validation dataset...\", end='')\n",
        "    val_acc = evaluate_model(model, v_loader)\n",
        "    mean_loss = np.mean(epoch_losses)\n",
        "\n",
        "    losses.append(mean_loss)\n",
        "    accs.append(val_acc)\n",
        "\n",
        "    if val_acc > best_acc:\n",
        "      best_acc = val_acc\n",
        "      best_model = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    print(f\"\\rEpoch: {epoch+1}/{n_epochs}, loss: {mean_loss}, validation accuracy: {val_acc}% took: {time.time() - start} seconds\")\n",
        "\n",
        "  print(f\"Training ended after {n_epochs} ! Best validation accuracy: {best_acc}%\")\n",
        "  try:\n",
        "    plot_training(losses, accs, n_epochs)\n",
        "  except:\n",
        "    print(\"error occurred when plotting losses and accuracy training data\")\n",
        "  return best_model, losses, accs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaXyrAEfvap6",
        "colab_type": "code",
        "outputId": "f849e944-bff6-4c6d-eed5-130964cd16ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# TODO: really take the last 2k images for testing\n",
        "train_dataset, val_dataset, test_dataset = extract_dataset(N_train, N_val, N_test, N_test_reserved, train_classes, max_padding=max_padding)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done extracting class: drums: 1 / 100\n",
            "done extracting class: traffic_light: 11 / 100\n",
            "done extracting class: face: 21 / 100\n",
            "done extracting class: clock: 31 / 100\n",
            "done extracting class: diving_board: 41 / 100\n",
            "done extracting class: hat: 51 / 100\n",
            "done extracting class: basketball: 61 / 100\n",
            "done extracting class: pencil: 71 / 100\n",
            "done extracting class: donut: 81 / 100\n",
            "done extracting class: ice_cream: 91 / 100\n",
            "training shape torch.Size([1300000, 3, 100])\n",
            "validation shape torch.Size([200000, 3, 100])\n",
            "testing shape torch.Size([20000, 3, 100])\n",
            "classes 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEGoqxR1y-6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaS_SobxWokC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "model = StrokeClassifier(conv1, hidden_size, n_layers, len(train_classes), bidirectional).to(device)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F2SK1L5YWOQ",
        "colab_type": "code",
        "outputId": "acc994e4-71af-45a9-8184-1a526c11d7a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "best_model, losses, accs = train_model(model, optimizer, loss_function, train_loader, val_loader, n_epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/20, loss: 2.4536612364550607, validation accuracy: 51.2745% took: 135.60530185699463 seconds\n",
            "Epoch: 2/20, loss: 1.1959330486744308, validation accuracy: 61.86% took: 135.5454399585724 seconds\n",
            "Epoch: 3/20, loss: 0.9697072131353515, validation accuracy: 66.186% took: 135.57814049720764 seconds\n",
            "Epoch: 4/20, loss: 0.8632060250068982, validation accuracy: 69.1325% took: 135.68995881080627 seconds\n",
            "Epoch: 5/20, loss: 0.7977692377241045, validation accuracy: 70.736% took: 135.61347246170044 seconds\n",
            "Epoch: 6/20, loss: 0.7525706450625606, validation accuracy: 71.8685% took: 135.69241857528687 seconds\n",
            "Epoch: 7/20, loss: 0.7200097752840272, validation accuracy: 72.947% took: 135.82915019989014 seconds\n",
            "Epoch: 8/20, loss: 0.6951407261558066, validation accuracy: 74.0475% took: 135.5016758441925 seconds\n",
            "batch: 1619, current loss: 0.6734559955127155"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bynKPlEifCuI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"Test accuracy: {evaluate_model(best_model, test_loader)}%\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaCHS8rMi7DK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "model_path = f'lstm_quickdraw.model.{time.time()}'\n",
        "torch.save(model, model_path)\n",
        "\n",
        "print(f\"Model saved at: {model_path}\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}