{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dl-project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP8F9yl3IGuYPC2IJnc+9Nf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cs-deep-quickdraw/notebooks/blob/master/notebooks/dl_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvWSI630bwxU",
        "colab_type": "code",
        "outputId": "2a4fdef7-07e7-48d5-a51e-dd7bbdaecf11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget 'https://raw.githubusercontent.com/cs-deep-quickdraw/notebooks/master/100_classes.txt'\n",
        "!mkdir data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-17 16:22:07--  https://raw.githubusercontent.com/cs-deep-quickdraw/notebooks/master/100_classes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 760 [text/plain]\n",
            "Saving to: ‘100_classes.txt’\n",
            "\n",
            "\r100_classes.txt       0%[                    ]       0  --.-KB/s               \r100_classes.txt     100%[===================>]     760  --.-KB/s    in 0s      \n",
            "\n",
            "2020-02-17 16:22:07 (58.4 MB/s) - ‘100_classes.txt’ saved [760/760]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZKiRERqbxgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib.request\n",
        "\n",
        "f = open(\"100_classes.txt\",\"r\")\n",
        "# And for reading use\n",
        "classes = [cls.strip() for cls in f.readlines()]\n",
        "f.close()\n",
        "\n",
        "def download(classes):\n",
        "  base = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
        "  for i, c in enumerate(classes):\n",
        "    cls_url = c.replace('_', '%20')\n",
        "    path = base+cls_url+'.npy'\n",
        "    print((1+i)/len(classes), c, path)\n",
        "    urllib.request.urlretrieve(path, 'data/'+c+'.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igZFGfx8bxi_",
        "colab_type": "code",
        "outputId": "113a6a95-94c0-4625-9351-08401911b82d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "download(classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.01 drums https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/drums.npy\n",
            "0.02 sun https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sun.npy\n",
            "0.03 laptop https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/laptop.npy\n",
            "0.04 anvil https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/anvil.npy\n",
            "0.05 baseball_bat https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/baseball%20bat.npy\n",
            "0.06 ladder https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ladder.npy\n",
            "0.07 eyeglasses https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/eyeglasses.npy\n",
            "0.08 grapes https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/grapes.npy\n",
            "0.09 book https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/book.npy\n",
            "0.1 dumbbell https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dumbbell.npy\n",
            "0.11 traffic_light https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/traffic%20light.npy\n",
            "0.12 wristwatch https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wristwatch.npy\n",
            "0.13 wheel https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wheel.npy\n",
            "0.14 shovel https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shovel.npy\n",
            "0.15 bread https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bread.npy\n",
            "0.16 table https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/table.npy\n",
            "0.17 tennis_racquet https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tennis%20racquet.npy\n",
            "0.18 cloud https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cloud.npy\n",
            "0.19 chair https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/chair.npy\n",
            "0.2 headphones https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/headphones.npy\n",
            "0.21 face https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/face.npy\n",
            "0.22 eye https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/eye.npy\n",
            "0.23 airplane https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/airplane.npy\n",
            "0.24 snake https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/snake.npy\n",
            "0.25 lollipop https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lollipop.npy\n",
            "0.26 power_outlet https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/power%20outlet.npy\n",
            "0.27 pants https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pants.npy\n",
            "0.28 mushroom https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mushroom.npy\n",
            "0.29 star https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/star.npy\n",
            "0.3 sword https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sword.npy\n",
            "0.31 clock https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/clock.npy\n",
            "0.32 hot_dog https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hot%20dog.npy\n",
            "0.33 syringe https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/syringe.npy\n",
            "0.34 stop_sign https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/stop%20sign.npy\n",
            "0.35 mountain https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mountain.npy\n",
            "0.36 smiley_face https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/smiley%20face.npy\n",
            "0.37 apple https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/apple.npy\n",
            "0.38 bed https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bed.npy\n",
            "0.39 shorts https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shorts.npy\n",
            "0.4 broom https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/broom.npy\n",
            "0.41 diving_board https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/diving%20board.npy\n",
            "0.42 flower https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/flower.npy\n",
            "0.43 spider https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/spider.npy\n",
            "0.44 cell_phone https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cell%20phone.npy\n",
            "0.45 car https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/car.npy\n",
            "0.46 camera https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/camera.npy\n",
            "0.47 tree https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tree.npy\n",
            "0.48 square https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/square.npy\n",
            "0.49 moon https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/moon.npy\n",
            "0.5 radio https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/radio.npy\n",
            "0.51 hat https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hat.npy\n",
            "0.52 pizza https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pizza.npy\n",
            "0.53 axe https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/axe.npy\n",
            "0.54 door https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/door.npy\n",
            "0.55 tent https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tent.npy\n",
            "0.56 umbrella https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/umbrella.npy\n",
            "0.57 line https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/line.npy\n",
            "0.58 cup https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cup.npy\n",
            "0.59 fan https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/fan.npy\n",
            "0.6 triangle https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/triangle.npy\n",
            "0.61 basketball https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/basketball.npy\n",
            "0.62 pillow https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pillow.npy\n",
            "0.63 scissors https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/scissors.npy\n",
            "0.64 t-shirt https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/t-shirt.npy\n",
            "0.65 tooth https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tooth.npy\n",
            "0.66 alarm_clock https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/alarm%20clock.npy\n",
            "0.67 paper_clip https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/paper%20clip.npy\n",
            "0.68 spoon https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/spoon.npy\n",
            "0.69 microphone https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/microphone.npy\n",
            "0.7 candle https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/candle.npy\n",
            "0.71 pencil https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pencil.npy\n",
            "0.72 envelope https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/envelope.npy\n",
            "0.73 saw https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/saw.npy\n",
            "0.74 frying_pan https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/frying%20pan.npy\n",
            "0.75 screwdriver https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/screwdriver.npy\n",
            "0.76 helmet https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/helmet.npy\n",
            "0.77 bridge https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bridge.npy\n",
            "0.78 light_bulb https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/light%20bulb.npy\n",
            "0.79 ceiling_fan https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ceiling%20fan.npy\n",
            "0.8 key https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/key.npy\n",
            "0.81 donut https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/donut.npy\n",
            "0.82 bird https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bird.npy\n",
            "0.83 circle https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/circle.npy\n",
            "0.84 beard https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/beard.npy\n",
            "0.85 coffee_cup https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/coffee%20cup.npy\n",
            "0.86 butterfly https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/butterfly.npy\n",
            "0.87 bench https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bench.npy\n",
            "0.88 rifle https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rifle.npy\n",
            "0.89 cat https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cat.npy\n",
            "0.9 sock https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sock.npy\n",
            "0.91 ice_cream https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ice%20cream.npy\n",
            "0.92 moustache https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/moustache.npy\n",
            "0.93 suitcase https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/suitcase.npy\n",
            "0.94 hammer https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hammer.npy\n",
            "0.95 rainbow https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rainbow.npy\n",
            "0.96 knife https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/knife.npy\n",
            "0.97 cookie https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cookie.npy\n",
            "0.98 baseball https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/baseball.npy\n",
            "0.99 lightning https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lightning.npy\n",
            "1.0 bicycle https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bicycle.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXQ6O2-Sbxli",
        "colab_type": "code",
        "outputId": "8bc22a22-fb9f-42db-af9e-cfc49ea96dbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "!ls data"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "airplane.npy\t  circle.npy\t    key.npy\t      shorts.npy\n",
            "alarm_clock.npy   clock.npy\t    knife.npy\t      shovel.npy\n",
            "anvil.npy\t  cloud.npy\t    ladder.npy\t      smiley_face.npy\n",
            "apple.npy\t  coffee_cup.npy    laptop.npy\t      snake.npy\n",
            "axe.npy\t\t  cookie.npy\t    light_bulb.npy    sock.npy\n",
            "baseball_bat.npy  cup.npy\t    lightning.npy     spider.npy\n",
            "baseball.npy\t  diving_board.npy  line.npy\t      spoon.npy\n",
            "basketball.npy\t  donut.npy\t    lollipop.npy      square.npy\n",
            "beard.npy\t  door.npy\t    microphone.npy    star.npy\n",
            "bed.npy\t\t  drums.npy\t    moon.npy\t      stop_sign.npy\n",
            "bench.npy\t  dumbbell.npy\t    mountain.npy      suitcase.npy\n",
            "bicycle.npy\t  envelope.npy\t    moustache.npy     sun.npy\n",
            "bird.npy\t  eyeglasses.npy    mushroom.npy      sword.npy\n",
            "book.npy\t  eye.npy\t    pants.npy\t      syringe.npy\n",
            "bread.npy\t  face.npy\t    paper_clip.npy    table.npy\n",
            "bridge.npy\t  fan.npy\t    pencil.npy\t      tennis_racquet.npy\n",
            "broom.npy\t  flower.npy\t    pillow.npy\t      tent.npy\n",
            "butterfly.npy\t  frying_pan.npy    pizza.npy\t      tooth.npy\n",
            "camera.npy\t  grapes.npy\t    power_outlet.npy  traffic_light.npy\n",
            "candle.npy\t  hammer.npy\t    radio.npy\t      tree.npy\n",
            "car.npy\t\t  hat.npy\t    rainbow.npy       triangle.npy\n",
            "cat.npy\t\t  headphones.npy    rifle.npy\t      t-shirt.npy\n",
            "ceiling_fan.npy   helmet.npy\t    saw.npy\t      umbrella.npy\n",
            "cell_phone.npy\t  hot_dog.npy\t    scissors.npy      wheel.npy\n",
            "chair.npy\t  ice_cream.npy     screwdriver.npy   wristwatch.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVj019Erch1C",
        "colab_type": "code",
        "outputId": "c6c69acc-58ef-492f-d55a-ee716ff38c28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Display one image\n",
        "test_cls = np.load(f'data/{classes[0]}.npy')\n",
        "print(f\"Test class: {classes[0]}\")\n",
        "\n",
        "f, (ax1, ax2, ax3, ax4, ax5, ax6, ax7) = plt.subplots(1, 7)\n",
        "\n",
        "ax1.imshow(test_cls[0].reshape(28, 28), cmap='gray')\n",
        "ax2.imshow(test_cls[1].reshape(28, 28), cmap='gray')\n",
        "ax3.imshow(test_cls[2].reshape(28, 28), cmap='gray')\n",
        "ax4.imshow(test_cls[3].reshape(28, 28), cmap='gray')\n",
        "ax5.imshow(test_cls[26001].reshape(28, 28), cmap='gray')\n",
        "ax6.imshow(test_cls[26002].reshape(28, 28), cmap='gray')\n",
        "ax7.imshow(test_cls[26003].reshape(28, 28), cmap='gray')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test class: drums\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fcc99da17b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAABLCAYAAACC5GfmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 7 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bz8Usye3fbO4",
        "colab_type": "code",
        "outputId": "35239c75-d831-4885-b33a-88287c62b635",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(test_cls))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "137299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QEKlYHDh7u6",
        "colab_type": "code",
        "outputId": "a8aa0fad-2ee3-40ca-f6fb-b8d5fa351fbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# check_classes = []\n",
        "# for i in range(100):\n",
        "#   check_classes.append(len(np.load(f'data/{classes[i]}.npy')))\n",
        "# print(check_classes)\n",
        "# print(min(check_classes))\n",
        "# print(max(check_classes))\n",
        "print('from 113862 to 290239 images per class')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "from 113862 to 290239 images per class\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3hrHA1Kf89G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_TEST = 20_000 # first 20k images are for test purpose"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRydtKHnch3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "class DrawDataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        assert len(self.X) == len(self.Y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        return [torch.Tensor(self.X[idx]).type('torch.FloatTensor'), self.Y[idx]]\n",
        "\n",
        "def load_dataset(max_classes=10, max_images_per_class=20000):\n",
        "  X = None\n",
        "  Y = []\n",
        "\n",
        "  for i, cls in enumerate(classes[:max_classes]):\n",
        "    data = np.load(f'data/{cls}.npy')[N_TEST:N_TEST+max_images_per_class].reshape(max_images_per_class, 1, 28, 28)\n",
        "    if X is not None:\n",
        "      X = np.concatenate((X, data))\n",
        "    else:\n",
        "      X = data\n",
        "\n",
        "    Y.extend([i for _ in range(max_images_per_class)])\n",
        "\n",
        "  return DrawDataset(X, Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZo6CHCjch6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = load_dataset(max_classes=100, max_images_per_class=20000)\n",
        "# TODO: we should do cross-validation here\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [int(0.8*len(dataset)), int(0.2*len(dataset))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8Krj0aAnWcX",
        "colab_type": "code",
        "outputId": "86359823-5308-4d54-8ad4-3304bd42ca62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(len(train_dataset))\n",
        "print(train_dataset[0][0].shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1600000\n",
            "torch.Size([1, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ig0cPDoQiUqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(train_dataset[0][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRj50Ng-lh-8",
        "colab_type": "code",
        "outputId": "5dbc13b6-1b64-4e96-d4dd-5b0f6256c5ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('device = {}'.format(device))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device = cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OT_p5KitnU6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "makYZv-KliDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "                 dataset=train_dataset,\n",
        "                 batch_size=batch_size,\n",
        "                 shuffle=True)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "                 dataset=val_dataset,\n",
        "                 batch_size=batch_size,\n",
        "                 shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9ZVydvQYE_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ17Os2kliGA",
        "colab_type": "code",
        "outputId": "0eaafda7-7757-4b07-88ad-d4b143172d11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('total training batch number: {}'.format(len(train_loader)))\n",
        "print('total validation batch number: {}'.format(len(val_loader)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total training batch number: 25000\n",
            "total validation batch number: 6250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8OmJg2XliBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# display some images\n",
        "# for an alternative see https://pytorch.org/tutorials/advanced/neural_style_tutorial.html\n",
        "# def imshow(tensor, title=None):\n",
        "#     img = tensor.cpu().clone()\n",
        "#     img = img.squeeze()\n",
        "#     plt.imshow(img, cmap='gray')\n",
        "#     if title is not None:\n",
        "#         plt.title(title)\n",
        "#     plt.pause(0.5)\n",
        "\n",
        "# plt.figure()\n",
        "# for ii in range(10):\n",
        "#     imshow(train_dataset[ii][0] , title='Example ({})'.format(classes[train_dataset[ii][1]]))\n",
        "# plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIuKPLScpD4l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define MLP model\n",
        "DATA_SIZE = 784\n",
        "NUM_HIDDEN_1 = 512 # try 512\n",
        "NUM_HIDDEN_2 = 256\n",
        "NUM_CLASSES = 100\n",
        "\n",
        "class MLPNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLPNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(DATA_SIZE, NUM_HIDDEN_1)\n",
        "        self.fc2 = nn.Linear(NUM_HIDDEN_1, NUM_HIDDEN_2)\n",
        "        self.fc3 = nn.Linear(NUM_HIDDEN_2, NUM_CLASSES)\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, DATA_SIZE) # reshape the tensor\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BN4IEULka66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define CNN model\n",
        "NUM_CONV_1=32\n",
        "NUM_CONV_2=64\n",
        "NUM_FC=1024\n",
        "class CNNNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNNet,self).__init__()\n",
        "        self.conv_1 = nn.Conv2d(1,NUM_CONV_1,5,1) # kernel_size = 5\n",
        "        self.conv_2 = nn.Conv2d(NUM_CONV_1,NUM_CONV_2,5,1) # kernel_size = 5\n",
        "        self.drop = nn.Dropout2d()\n",
        "        self.fc_1 = nn.Linear(4*4*NUM_CONV_2, NUM_FC)\n",
        "        self.fc_2 = nn.Linear(NUM_FC,NUM_CLASSES)\n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.conv_1(x))\n",
        "        x = F.max_pool2d(x, 2,2)\n",
        "        # x = F.relu(self.conv_2(x))\n",
        "        x = F.relu(self.drop(self.conv_2(x)))\n",
        "        x = F.max_pool2d(x, 2,2)\n",
        "        x = x.view(-1,4*4*NUM_CONV_2)\n",
        "        x = F.relu(self.fc_1(x))\n",
        "        x = self.fc_2(x)\n",
        "        return x\n",
        "        # en utilisant loss = F.nll_loss(output, target) on peut faire\n",
        "        # return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MzR-09KSSUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.models as models\n",
        "resnet = models.resnet18(pretrained=False)\n",
        "resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "# resnet.co = torch.nn.Linear(512, 102, bias = True)\n",
        "# resnet.co = torch.nn.Linear(512 * resnet.layer1[0].expansion,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysTJA6KmpD9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define model (choose MLP or CNN)\n",
        "# model = MLPNet()\n",
        "# model = CNNNet()\n",
        "model = resnet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb7Xo1XapEAA",
        "colab_type": "code",
        "outputId": "b7a12fb1-c94f-447e-83bb-539c8d96faf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.to(device) # puts model on GPU / CPU\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9bkkdCrpD7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# optimization hyperparameters\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.005)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr = 0.0005)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cbJoyJzb-gH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjL3JkC5WE3B",
        "colab_type": "code",
        "outputId": "1beef249-1a4a-40b5-ab21-2e0bb253837f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# main loop (train+test)\n",
        "N_EPOCHS = 10\n",
        "for epoch in range(N_EPOCHS):\n",
        "    losses = []\n",
        "    # training\n",
        "    model.train() # mode \"train\" agit sur \"dropout\" ou \"batchnorm\"\n",
        "    for batch_idx, (x, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        x, target = Variable(x).to(device), Variable(target).to(device)\n",
        "        out = model(x)\n",
        "        loss = loss_fn(out, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "        # if batch_idx %100 ==0:\n",
        "        #     print('epoch {} batch {} [{}/{}] training loss: {}'.format(epoch,batch_idx,batch_idx*len(x),\n",
        "        #             len(train_loader.dataset),loss.item()))\n",
        "\n",
        "    # testing\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (x, target) in enumerate(val_loader):\n",
        "            x, target = x.to(device), target.to(device)\n",
        "            out = model(x)\n",
        "            loss = loss_fn(out, target)\n",
        "            # _, prediction = torch.max(out.data, 1)\n",
        "            prediction = out.argmax(dim=1, keepdim=True) # index of the max log-probability\n",
        "            correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
        "    taux_classif = 100. * correct / len(val_loader.dataset)\n",
        "    print(f'Epoch {epoch+1}/{N_EPOCHS}: Loss: {np.mean(losses)}, Val Accuracy: {correct}/{len(val_loader.dataset)} (tx {taux_classif}%, err {100.-taux_classif}%)\\n')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10: Loss: 1.1501512489032746, Val Accuracy: 314111/400000 (tx 78.52775%, err 21.472250000000003%)\n",
            "\n",
            "Epoch 2/10: Loss: 0.7883832345503569, Val Accuracy: 323369/400000 (tx 80.84225%, err 19.157749999999993%)\n",
            "\n",
            "Epoch 3/10: Loss: 0.7020196860712766, Val Accuracy: 327910/400000 (tx 81.9775%, err 18.022499999999994%)\n",
            "\n",
            "Epoch 4/10: Loss: 0.6505148977184295, Val Accuracy: 330425/400000 (tx 82.60625%, err 17.393749999999997%)\n",
            "\n",
            "Epoch 5/10: Loss: 0.6117653136605025, Val Accuracy: 331672/400000 (tx 82.918%, err 17.081999999999994%)\n",
            "\n",
            "Epoch 6/10: Loss: 0.5815117141139508, Val Accuracy: 333296/400000 (tx 83.324%, err 16.676000000000002%)\n",
            "\n",
            "Epoch 7/10: Loss: 0.5553202882653475, Val Accuracy: 334004/400000 (tx 83.501%, err 16.498999999999995%)\n",
            "\n",
            "Epoch 8/10: Loss: 0.5316642516076565, Val Accuracy: 334339/400000 (tx 83.58475%, err 16.41525%)\n",
            "\n",
            "Epoch 9/10: Loss: 0.5103664493459463, Val Accuracy: 334885/400000 (tx 83.72125%, err 16.278750000000002%)\n",
            "\n",
            "Epoch 10/10: Loss: 0.4904812931293249, Val Accuracy: 334805/400000 (tx 83.70125%, err 16.29875%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVhJpadmWE5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0fAEnaEWE8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWOsB_hBWFL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5tn0h1tWE0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}